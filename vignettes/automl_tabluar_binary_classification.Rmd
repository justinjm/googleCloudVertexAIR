---
title: "AutoML training tabular binary classification model for batch predictionÂ¶"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{datasets}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Overview

Emulation of notebook tutorial using Vertex AI SDK via Python: [vertex-ai-samples/automl-tabular-classification.ipynb at master \| GoogleCloudPlatform/vertex-ai-samples](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/automl/automl-tabular-classification.ipynb)

# Setup

## Installation

Run the following chunk to install `googleCloudVertexAIR` and the other required R packages to complete this tutorial (checking to see if they are installed first and only install if not already): 

```{r install_packages, eval=FALSE}
list.of.packages <- c("remotes", "googleAuthR")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

remotes::install_github("justinjm/googleCloudVertexAIR")
``` 



## Setup Google Cloud Project

## Authenticate your Google Cloud Account

## Create a Cloud Storage bucket

# Tutorial

## Create Dataset

## Train Model

### Create and run training pipeline

To train an AutoML tabular binary classification model, you perform two steps: 1) create a training pipeline, and 2) run the pipeline.

#### Create training pipeline

#### Run the training pipeline

## Model deployment for batch prediction

Now deploy the trained Vertex`Model`resource you created for batch prediction. This differs from deploying a`Model`resource for online prediction.

For online prediction, you:

1.  Create an`Endpoint`resource for deploying the`Model`resource to.
2.  Deploy the`Model`resource to the`Endpoint`resource.
3.  Make online prediction requests to the`Endpoint`resource.

For batch-prediction, you:

1.  Create a batch prediction job.
2.  The job service will provision resources for the batch prediction request.
3.  The results of the batch prediction request are returned to the caller.
4.  The job service will unprovision the resoures for the batch prediction request.

## Make a batch prediction request

### Make test items

### Make batch input file

### Make the batch prediction request

### Wait for completion of batch prediction job

### Get predictions

## Cleaning up
